{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业说明：\n",
    "\n",
    "**作业1:飞桨本地安装**\n",
    "\n",
    "**提交飞桨本地安装成功的截图**，如下图所示，有安装问题可以随时在群里提问，可参考飞桨官网：https://www.paddlepaddle.org.cn/documentation/docs/zh/install/index_cn.html\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/c93925b52b2f4f9dbeb62569122924f9ee3b6c69c3b14219a74425d8360d6639\" height=\"200\" width=\"400\" />\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "**作业2：新冠疫情可视化**\n",
    "\n",
    "请根据课上所学内容，爬取3月31日当天丁香园公开的统计数据，根据累计确诊数，使用pyecharts绘制疫情分布图，如下图所示，**提交截图。**\n",
    "\n",
    "Pycharts api可参考：https://pyecharts.org/#/zh-cn/\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/24a15aae792b49ecb4b11aa30530e97691a092ef2af94f9f97751826096b4cc8\" height=\"200\" width=\"400\" />\n",
    "\n",
    "\n",
    "**重要：**\n",
    "\n",
    "**一定要用正确的姿势在Notebook上传图片+生成版本作业提交示例：** https://aistudio.baidu.com/aistudio/projectDetail/296022\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化，是一种利用计算机图形学和图像处理技术，将数据转换成图像在屏幕上显示出来，再进行交互处理的理论、方法和技术。\n",
    "\n",
    "**本次实践基于丁香园公开的统计数据，实现新冠疫情可视化，包括疫情地图、疫情增长趋势图、疫情分布图等。**\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "**全国疫情地图如下：**\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/3ca5fa8e7019498ab7217aea7a552f0394ff092045174b9284920dbee57b0c1a\" height=\"500\" width=\"500\" />\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "**疫情增长趋势图如下：**\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/28000edb58d34e2e991b6dc2739007ae837b9b031d8842528c9d9506941fbd17\" height=\"500\" width=\"600\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、数据准备\n",
    "\n",
    "上网的全过程:\n",
    "\n",
    "- 普通用户\n",
    "\n",
    " 打开浏览器 --> 往目标站点发送请求 --> 接收响应数据 --> 渲染到页面上。\n",
    "                 \n",
    "- 爬虫程序\n",
    "\n",
    "模拟浏览器 --> 往目标站点发送请求 --> 接收响应数据 --> 提取有用的数据 --> 保存到本地/数据库。\n",
    "\n",
    "<br />\n",
    "\n",
    "爬虫的过程：\n",
    "\n",
    "1.发送请求（requests模块）\n",
    "\n",
    "2.获取响应数据（服务器返回）\n",
    "\n",
    "3.解析并提取数据（re正则）\n",
    "\n",
    "4.保存数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**request模块：**\n",
    "\n",
    "requests是python实现的简单易用的HTTP库，官网地址：http://cn.python-requests.org/zh_CN/latest/\n",
    "\n",
    "**re模块：**\n",
    "\n",
    "re模块是python用于匹配字符串的模块，该模块中提供的很多功能是基于正则表达式实现的，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "today = datetime.date.today().strftime('%Y%m%d')   #20200315\n",
    "\n",
    "def crawl_dxy_data():\n",
    "    \"\"\"\n",
    "    爬取丁香园实时统计数据，保存到data目录下，以当前日期作为文件名，存JSON文件\n",
    "    \"\"\"\n",
    "    response = requests.get('https://ncov.dxy.cn/ncovh5/view/pneumonia') #request.get()用于请求目标网站\n",
    "    print(response.status_code)                                          # 打印状态码\n",
    "\n",
    "\n",
    "    try:\n",
    "        url_text = response.content.decode()                             #更推荐使用response.content.deocde()的方式获取响应的html页面\n",
    "        #print(url_text)\n",
    "        url_content = re.search(r'window.getAreaStat = (.*?)}]}catch',   #re.search():扫描字符串以查找正则表达式模式产生匹配项的第一个位置 ，然后返回相应的match对象。\n",
    "                                url_text, re.S)                          #在字符串a中，包含换行符\\n，在这种情况下：如果不使用re.S参数，则只在每一行内进行匹配，如果一行没有，就换下一行重新开始;\n",
    "                                                                         #而使用re.S参数以后，正则表达式会将这个字符串作为一个整体，在整体中进行匹配。\n",
    "        texts = url_content.group()                                      #获取匹配正则表达式的整体结果\n",
    "        content = texts.replace('window.getAreaStat = ', '').replace('}catch', '') #去除多余的字符\n",
    "        json_data = json.loads(content)                                         \n",
    "        with open('data/' + today + '.json', 'w', encoding='UTF-8') as f:\n",
    "            json.dump(json_data, f, ensure_ascii=False)\n",
    "    except:\n",
    "        print('<Response [%s]>' % response.status_code)\n",
    "\n",
    "\n",
    "def crawl_statistics_data():\n",
    "    \"\"\"\n",
    "    获取各个省份历史统计数据，保存到data目录下，存JSON文件\n",
    "    \"\"\"\n",
    "    with open('data/'+ today + '.json', 'r', encoding='UTF-8') as file:\n",
    "        json_array = json.loads(file.read())\n",
    "\n",
    "    statistics_data = {}\n",
    "    for province in json_array:\n",
    "        response = requests.get(province['statisticsData'])\n",
    "        try:\n",
    "            statistics_data[province['provinceShortName']] = json.loads(response.content.decode())['data']\n",
    "        except:\n",
    "            print('<Response [%s]> for url: [%s]' % (response.status_code, province['statisticsData']))\n",
    "\n",
    "    with open(\"data/statistics_data.json\", \"w\", encoding='UTF-8') as f:\n",
    "        json.dump(statistics_data, f, ensure_ascii=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    crawl_dxy_data()\n",
    "    crawl_statistics_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting pyecharts\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8b/87/d358d00c8e7837da835869afa34cf556dc743a20d92d67abe02529c7b1d8/pyecharts-1.7.1-py3-none-any.whl (128kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 113kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: prettytable in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pyecharts) (0.7.2)\n",
      "Collecting simplejson (from pyecharts)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/98/87/a7b98aa9256c8843f92878966dc3d8d914c14aad97e2c5ce4798d5743e07/simplejson-3.17.0.tar.gz (83kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 4.0MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pyecharts) (2.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jinja2->pyecharts) (1.1.1)\n",
      "Building wheels for collected packages: simplejson\n",
      "  Building wheel for simplejson (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for simplejson: filename=simplejson-3.17.0-cp37-cp37m-linux_x86_64.whl size=117561 sha256=d6281dee95022ba03fccaa0686aaa17a809a2dac383cc9d682e65e60caf931c4\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/a3/ff/91/28cf8f5773074d4b84507bafceb766170a7f7343247351a99f\n",
      "Successfully built simplejson\n",
      "Installing collected packages: simplejson, pyecharts\n",
      "Successfully installed pyecharts-1.7.1 simplejson-3.17.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "安装第三方库pyecharts ，如果下载时出现断线和速度过慢的问题导致下载失败，可以尝试使用清华镜像\n",
    "'''\n",
    "#!pip install pyecharts\n",
    "!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pyecharts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、疫情地图\n",
    "\n",
    "Echarts 是一个由百度开源的数据可视化工具，凭借着良好的交互性，精巧的图表设计，得到了众多开发者的认可。而 Python 是一门富有表达力的语言，很适合用于数据处理。当数据分析遇上数据可视化时，**pyecharts** 诞生了。pyecharts api可以参考：https://pyecharts.org/#/zh-cn/chart_api\n",
    "\n",
    "<br />\n",
    "<br/>\n",
    "\n",
    "**使用 options 配置项，在 pyecharts 中，一切皆 Options。**\n",
    "\n",
    "主要分为全局配置组件和系列配置组件。\n",
    "\n",
    "（1）系列配置项 set_series_opts(),可配置图元样式、文字样式、标签样式、点线样式等；   \n",
    "\n",
    "（2）全局配置项 set_global_opts()，可配置标题、动画、坐标轴、图例等;                       \n",
    "\n",
    "先来认识下全局配置组件吧\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/dc6f8d74e83a49ccb2ce5d0c2d8518fc7e731d1d203a4ec4ace84d6aacf73910\" height=\"600\" width=\"700\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1全国疫情地图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('湖北', 67801), ('广东', 1490), ('河南', 1276), ('浙江', 1257), ('湖南', 1018), ('安徽', 990), ('江西', 937), ('山东', 774), ('香港', 682), ('江苏', 646), ('北京', 580), ('重庆', 579), ('四川', 550), ('上海', 509), ('黑龙江', 484), ('福建', 343), ('河北', 321), ('台湾', 306), ('广西', 254), ('陕西', 253), ('云南', 181), ('天津', 174), ('海南', 168), ('贵州', 147), ('辽宁', 139), ('甘肃', 138), ('山西', 136), ('内蒙古', 107), ('吉林', 98), ('新疆', 76), ('宁夏', 75), ('澳门', 39), ('青海', 18), ('西藏', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/aistudio/data/全国实时确诊数据.html'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "from pyecharts.charts import Map\n",
    "from pyecharts import options as opts\n",
    "\n",
    "# 读原始数据文件\n",
    "today = datetime.date.today().strftime('%Y%m%d')   #20200315\n",
    "datafile = 'data/'+ today + '.json'\n",
    "with open(datafile, 'r', encoding='UTF-8') as file:\n",
    "    json_array = json.loads(file.read())\n",
    "\n",
    "# 分析全国实时确诊数据：'confirmedCount'字段\n",
    "china_data = []\n",
    "for province in json_array:\n",
    "    china_data.append((province['provinceShortName'], province['confirmedCount']))\n",
    "china_data = sorted(china_data, key=lambda x: x[1], reverse=True)                 #reverse=True,表示降序，反之升序\n",
    "\n",
    "print(china_data)\n",
    "# 全国疫情地图\n",
    "# 自定义的每一段的范围，以及每一段的特别的样式。\n",
    "pieces = [\n",
    "    {'min': 10000, 'color': '#540d0d'},\n",
    "    {'max': 9999, 'min': 1000, 'color': '#9c1414'},\n",
    "    {'max': 999, 'min': 500, 'color': '#d92727'},\n",
    "    {'max': 499, 'min': 100, 'color': '#ed3232'},\n",
    "    {'max': 99, 'min': 10, 'color': '#f27777'},\n",
    "    {'max': 9, 'min': 1, 'color': '#f7adad'},\n",
    "    {'max': 0, 'color': '#f7e4e4'},\n",
    "]\n",
    "labels = [data[0] for data in china_data]\n",
    "counts = [data[1] for data in china_data]\n",
    "\n",
    "m = Map()\n",
    "m.add(\"累计确诊\", [list(z) for z in zip(labels, counts)], 'china')\n",
    "\n",
    "#系列配置项,可配置图元样式、文字样式、标签样式、点线样式等\n",
    "m.set_series_opts(label_opts=opts.LabelOpts(font_size=12),\n",
    "                  is_show=False)\n",
    "#全局配置项,可配置标题、动画、坐标轴、图例等\n",
    "m.set_global_opts(title_opts=opts.TitleOpts(title='全国实时确诊数据',\n",
    "                                            subtitle='数据来源：丁香园'),\n",
    "                  legend_opts=opts.LegendOpts(is_show=False),\n",
    "                  visualmap_opts=opts.VisualMapOpts(pieces=pieces,\n",
    "                                                    is_piecewise=True,   #是否为分段型\n",
    "                                                    is_show=True))       #是否显示视觉映射配置\n",
    "#render（）会生成本地 HTML 文件，默认会在当前目录生成 render.html 文件，也可以传入路径参数，如 m.render(\"mycharts.html\")\n",
    "m.render(path='/home/aistudio/data/全国实时确诊数据.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2湖北省疫情地图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('武汉市', 50006), ('孝感市', 3518), ('黄冈市', 2907), ('荆州市', 1580), ('鄂州市', 1394), ('随州市', 1307), ('襄阳市', 1175), ('黄石市', 1015), ('宜昌市', 931), ('荆门市', 928), ('咸宁市', 836), ('十堰市', 672), ('仙桃市', 575), ('天门市', 496), ('恩施土家族苗族自治州', 252), ('潜江市', 198), ('神农架林区', 11)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/aistudio/data/湖北省实时确诊数据.html'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "from pyecharts.charts import Map\n",
    "from pyecharts import options as opts\n",
    "\n",
    "# 读原始数据文件\n",
    "today = datetime.date.today().strftime('%Y%m%d')   #20200315\n",
    "datafile = 'data/'+ today + '.json'\n",
    "with open(datafile, 'r', encoding='UTF-8') as file:\n",
    "    json_array = json.loads(file.read())\n",
    "\n",
    "# 分析湖北省实时确诊数据\n",
    "# 读入规范化的城市名称，用于规范化丁香园数据中的城市简称\n",
    "with open('/home/aistudio/data/data24815/pycharts_city.txt', 'r', encoding='UTF-8') as f:\n",
    "    defined_cities = [line.strip() for line in f.readlines()]\n",
    "\n",
    "\n",
    "def format_city_name(name, defined_cities):\n",
    "    for defined_city in defined_cities:\n",
    "        if len((set(defined_city) & set(name))) == len(name):\n",
    "            name = defined_city\n",
    "            if name.endswith('市') or name.endswith('区') or name.endswith('县') or name.endswith('自治州'):\n",
    "                return name\n",
    "            return name + '市'\n",
    "    return None\n",
    "\n",
    "\n",
    "province_name = '湖北'\n",
    "for province in json_array:\n",
    "    if province['provinceName'] == province_name or province['provinceShortName'] == province_name:\n",
    "        json_array_province = province['cities']\n",
    "        hubei_data = [(format_city_name(city['cityName'], defined_cities), city['confirmedCount']) for city in\n",
    "                      json_array_province]\n",
    "        hubei_data = sorted(hubei_data, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        print(hubei_data)\n",
    "\n",
    "labels = [data[0] for data in hubei_data]\n",
    "counts = [data[1] for data in hubei_data]\n",
    "pieces = [\n",
    "    {'min': 10000, 'color': '#540d0d'},\n",
    "    {'max': 9999, 'min': 1000, 'color': '#9c1414'},\n",
    "    {'max': 999, 'min': 500, 'color': '#d92727'},\n",
    "    {'max': 499, 'min': 100, 'color': '#ed3232'},\n",
    "    {'max': 99, 'min': 10, 'color': '#f27777'},\n",
    "    {'max': 9, 'min': 1, 'color': '#f7adad'},\n",
    "    {'max': 0, 'color': '#f7e4e4'},\n",
    "]\n",
    "\n",
    "m = Map()\n",
    "m.add(\"累计确诊\", [list(z) for z in zip(labels, counts)], '湖北')\n",
    "m.set_series_opts(label_opts=opts.LabelOpts(font_size=12),\n",
    "                  is_show=False)\n",
    "m.set_global_opts(title_opts=opts.TitleOpts(title='湖北省实时确诊数据',\n",
    "                                            subtitle='数据来源：丁香园'),\n",
    "                  legend_opts=opts.LegendOpts(is_show=False),\n",
    "                  visualmap_opts=opts.VisualMapOpts(pieces=pieces,\n",
    "                                                    is_piecewise=True,\n",
    "                                                    is_show=True))\n",
    "m.render(path='/home/aistudio/data/湖北省实时确诊数据.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、疫情增长趋势图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aistudio/data/新增确诊趋势图.html'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from pyecharts.charts import Line\n",
    "from pyecharts import options as opts\n",
    "\n",
    "# 读原始数据文件\n",
    "datafile = 'data/statistics_data.json'\n",
    "with open(datafile, 'r', encoding='UTF-8') as file:\n",
    "    json_dict = json.loads(file.read())\n",
    "\n",
    "# 分析各省份2月1日至今的新增确诊数据：'confirmedIncr'\n",
    "statistics__data = {}\n",
    "for province in json_dict:\n",
    "    statistics__data[province] = []\n",
    "    for da in json_dict[province]:\n",
    "        if da['dateId'] >= 20200201:\n",
    "            statistics__data[province].append(da['confirmedIncr'])\n",
    "\n",
    "# 获取日期列表\n",
    "dateId = [str(da['dateId'])[4:6] + '-' + str(da['dateId'])[6:8] for da in json_dict['湖北'] if\n",
    "          da['dateId'] >= 20200201]\n",
    "\n",
    "# 全国新增趋势\n",
    "all_statis = np.array([0] * len(dateId))\n",
    "for province in statistics__data:\n",
    "    all_statis = all_statis + np.array(statistics__data[province])\n",
    "\n",
    "all_statis = all_statis.tolist()\n",
    "# 湖北新增趋势\n",
    "hubei_statis = statistics__data['湖北']\n",
    "# 湖北以外的新增趋势\n",
    "other_statis = [all_statis[i] - hubei_statis[i] for i in range(len(dateId))]\n",
    "\n",
    "line = Line()\n",
    "line.add_xaxis(dateId)\n",
    "line.add_yaxis(\"全国新增确诊病例\",   #图例\n",
    "                all_statis,       #数据\n",
    "                is_smooth=True,   #是否平滑曲线\n",
    "               linestyle_opts=opts.LineStyleOpts(width=4, color='#B44038'),#线样式配置项\n",
    "               itemstyle_opts=opts.ItemStyleOpts(color='#B44038',          #图元样式配置项\n",
    "                                                 border_color=\"#B44038\",   #颜色\n",
    "                                                 border_width=10))         #图元的大小\n",
    "line.add_yaxis(\"湖北新增确诊病例\", hubei_statis, is_smooth=True,\n",
    "               linestyle_opts=opts.LineStyleOpts(width=2, color='#4E87ED'),\n",
    "               label_opts=opts.LabelOpts(position='bottom'),              #标签在折线的底部\n",
    "               itemstyle_opts=opts.ItemStyleOpts(color='#4E87ED',\n",
    "                                                 border_color=\"#4E87ED\",\n",
    "                                                 border_width=3))\n",
    "line.add_yaxis(\"其他省份新增病例\", other_statis, is_smooth=True,\n",
    "               linestyle_opts=opts.LineStyleOpts(width=2, color='#F1A846'),\n",
    "               label_opts=opts.LabelOpts(position='bottom'),              #标签在折线的底部\n",
    "               itemstyle_opts=opts.ItemStyleOpts(color='#F1A846',\n",
    "                                                 border_color=\"#F1A846\",\n",
    "                                                 border_width=3))\n",
    "line.set_global_opts(title_opts=opts.TitleOpts(title=\"新增确诊病例\", subtitle='数据来源：丁香园'),\n",
    "                     yaxis_opts=opts.AxisOpts(max_=16000, min_=1, type_=\"log\",    #坐标轴配置项\n",
    "                                              splitline_opts=opts.SplitLineOpts(is_show=True),#分割线配置项\n",
    "                                              axisline_opts=opts.AxisLineOpts(is_show=True)))#坐标轴刻度线配置项\n",
    "line.render(path='/home/aistudio/data/新增确诊趋势图.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 请在以下cell中完成作业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aistudio/data/全国实时确诊数据.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\r\n",
    "import datetime\r\n",
    "from pyecharts.charts import Map, Pie\r\n",
    "from pyecharts import options as opts\r\n",
    "\r\n",
    "# 读原始数据文件\r\n",
    "today = datetime.date.today().strftime('%Y%m%d')   #20200315\r\n",
    "datafile = 'data/'+ today + '.json'\r\n",
    "with open(datafile, 'r', encoding='UTF-8') as file:\r\n",
    "    json_array = json.loads(file.read())\r\n",
    "\r\n",
    "# 分析全国实时确诊数据：'confirmedCount'字段\r\n",
    "china_data = []\r\n",
    "for province in json_array:\r\n",
    "    china_data.append([province['provinceShortName'], province['confirmedCount']])\r\n",
    "china_data = sorted(china_data, key=lambda x: x[1], reverse=True)                 #reverse=True,表示降序，反之升序\r\n",
    "\r\n",
    "# china_data, len(china_data)\r\n",
    "\r\n",
    "for i in range(len(china_data)):\r\n",
    "    label, cnt = china_data[i]\r\n",
    "    china_data[i][0] = f'{label}:{cnt}'\r\n",
    "\r\n",
    "m = Pie(opts.InitOpts(width='700px', height='1000px'))\r\n",
    "m.add(\"\", china_data, center=[\"50%\", \"50%\"],)\r\n",
    "\r\n",
    "# #系列配置项,可配置图元样式、文字样式、标签样式、点线样式等\r\n",
    "m.set_series_opts(label_opts=opts.LabelOpts(font_size=12),\r\n",
    "                #   is_show=False\r\n",
    "                )\r\n",
    "#全局配置项,可配置标题、动画、坐标轴、图例等\r\n",
    "m.set_global_opts(\r\n",
    "                #   title_opts=opts.TitleOpts(title='全国实时确诊数据',\r\n",
    "                #                             subtitle='数据来源：丁香园'),\r\n",
    "                  legend_opts=opts.LegendOpts(is_show=False),\r\n",
    "                #   datazoom_opts = opts.DataZoomOpts(is_show=True),\r\n",
    "                #   visualmap_opts=opts.VisualMapOpts(pieces=pieces,\r\n",
    "                #                                     is_piecewise=True,   #是否为分段型\r\n",
    "                #                                     is_show=True)        #是否显示视觉映射配置\r\n",
    "                )       \r\n",
    "# #render（）会生成本地 HTML 文件，默认会在当前目录生成 render.html 文件，也可以传入路径参数，如 m.render(\"mycharts.html\")\r\n",
    "m.render(path='/home/aistudio/data/全国实时确诊数据.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# help(m.add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 请将作业截图进行上传"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/74215e81fad947f3b7d9170f90211aa57837bed45c144ec4b01d1b52485dcccf)\n",
    "\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/673c1ae642ff49e8a4c4a7c9fb6c7dd20fd8f12d162f42c89688c0285ddb6805)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
